knitr::opts_chunk$set(echo = TRUE)
#install.packages("caret")
#install.packages("rpart.plot")
#install.packages("cluster")
#install.packages("factoextra")
#install.packages("NbClust")
library(tidyverse)
library(caret)
library(rpart.plot)
library(cluster)
library(factoextra)
library(magrittr)
library(NbClust)
library(tidyverse)
library(caret)
library(rpart.plot)
library(cluster)
library(factoextra)
library(magrittr)
library(NbClust)
jugadores <- read.csv("C:/Users/Usuario/Documents/GitHub/futbol-data-science/clase-8/jugadores_superliga_argentina.csv", sep = ',', header = FALSE)
jugadores <- read.csv("C:/Users/Usuario/Documents/GitHub/futbol-data-science/clase-8/jugadores_superliga_argentina.csv", sep = ',', header = TRUE)
jugadores <- read.csv("C:/Users/Usuario/Documents/GitHub/futbol-data-science/clase-8/jugadores_superliga_argentina.csv", sep = ',', header = TRUE)
glimpse(jugadores)
#Trateremos de predecir la clase o variable target llamada "V7"
unique(jugadores$position)
glimpse(jugadores)
grep("CF",jugadores$position)
ifelse(grep("CF",jugadores$position), "si", "no")
ifelse(grepl("CF",jugadores$position), "si", "no")
jugadores$es_CF <- ifelse(grepl("CF",jugadores$position), "si", "no")
jugadores
View(jugadores)
View(jugadores)
jugadores$es_CF
names(jugadores)
set.seed(3033)
#el parámetro p marca la proporción del dataset que va a estar destinada a entrenamiento. también le indicamos la variable target.
intrain <- createDataPartition(y = jugadores$es_CF, p= 0.7, list = FALSE)
training <- jugadores[intrain,]
testing <- jugadores[-intrain,]
#chequeamos como quedamor training y test
dim(training)
dim(testing)
#chequeamos si tiene NA
anyNA(jugadores)
#chequeamos si tiene NA
na.omit(jugadores)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(1234)
jugadores <- jugadores %>% sample_n(10000)
#el parámetro p marca la proporción del dataset que va a estar destinada a entrenamiento. también le indicamos la variable target.
intrain <- createDataPartition(y = jugadores$es_CF, p= 0.7, list = FALSE)
training <- jugadores[intrain,]
testing <- jugadores[-intrain,]
#chequeamos como quedamor training y test
dim(training)
dim(testing)
#chequeamos si tiene NA
na.omit(jugadores)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
dtree_fit <- train(es_CF ~., data = training, method = "rpart",
parms = list(split = "information"),
trControl=trctrl,
tuneLength = 10)
jugadores$competition
View(jugadores)
jugadores <- read.csv("C:/Users/Usuario/Documents/GitHub/futbol-data-science/clase-8/jugadores_superliga_argentina.csv", sep = ',', header = TRUE, encoding = 'UTF-8')
jugadores$es_CF <- ifelse(grepl("CF",jugadores$position), "si", "no")
jugadores <- jugadores %>% sample_n(10000)
names(jugadores)
na_count <-sapply(x, function(y) sum(length(which(is.na(y)))))
na_count <-sapply(jugadores, function(y) sum(length(which(is.na(y)))))
na_count
jugadores %>% select(-...72, -...73, -short_passes_accurate, -total_short_passes, -team:position)
jugadores %>% select(-short_passes_accurate, -total_short_passes, -team:position)
jugadores %>% select(-short_passes_accurate, -total_short_passes, -team, -player, -match, -competition, -date, -position, -...72, -...73)
jugadores <- jugadores %>% select(-short_passes_accurate, -total_short_passes, -team, -player, -match, -competition, -date, -position, -...72, -...73)
na.omit(jugadores)
jugadores <- na.omit(jugadores)
#el parámetro p marca la proporción del dataset que va a estar destinada a entrenamiento. también le indicamos la variable target.
intrain <- createDataPartition(y = jugadores$es_CF, p= 0.7, list = FALSE)
training <- jugadores[intrain,]
testing <- jugadores[-intrain,]
#chequeamos como quedamor training y test
dim(training)
dim(testing)
dtree_fit <- train(es_CF ~., data = training, method = "rpart",
parms = list(split = "information"),
trControl=trctrl,
tuneLength = 10)
dtree_fit
#metodo usado
dtree_fit$method
#modelo mejor "tuneado". Es el que el parámetro cp (complexity parameter) es menor.
dtree_fit$bestTune
#ploteamos
prp(modelo_arbol$finalModel, box.palette = "Reds", tweak = 1.2)
modelo_arbol <- train(es_CF ~., data = training, method = "rpart",
parms = list(split = "information"),
trControl=trctrl,
tuneLength = 10)
modelo_arbol
#metodo usado
modelo_arbol$method
#modelo mejor "tuneado". Es el que el parámetro cp (complexity parameter) es menor.
modelo_arbol$bestTune
#ploteamos
prp(modelo_arbol$finalModel, box.palette = "Reds", tweak = 1.2)
#vamos a predecir la clase del primer registro de test
testing[1,]
#vamos a predecir la clase del primer registro de test
testing[1,]
#vamos a predecir la clase del primer registro de test
testing[1,'es_Cf']
#vamos a predecir la clase del primer registro de test
testing[1,'es_CF']
#vemos que el modelo predice bien!
predict(modelo_arbol, newdata = testing[1,])
#vamos a analizar las predicciones de todo el testing
test_pred <- predict(dtree_fit, newdata = testing)
confusionMatrix(test_pred, testing$es_CF)  #Chequeamos "accuracy"
as.factor(testing$es_CF)
testing$es_CF <- as.factor(testing$es_CF)
confusionMatrix(test_pred, testing$es_CF)  #Chequeamos "accuracy"
