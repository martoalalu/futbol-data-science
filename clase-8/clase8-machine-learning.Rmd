---
title: "clase3-tidyverse"
author: "Martín Alalu & Ramiro Fernández"
date: "26/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
1. Cargamos las librerías necesarias para la clase
```{r}
#install.packages("caret")
#install.packages("rpart.plot")
#install.packages("cluster")
#install.packages("factoextra")
#install.packages("NbClust")
library(tidyverse)
library(caret)
library(rpart.plot)
library(cluster)
library(factoextra)
library(magrittr)
library(NbClust)
```

### Aprendizaje basado en Árboles de Decisión

Vamos a ver una implementación de modelos árboles de decisión, englobado una categoría más amplia denominada ```Classification and Regression Trees``` (CART). En particular vamos a ver un algoritmo llamado Recursive Partitioning and Regression Trees o RPART.

Para aplicar RPART, vamos a usar el paquete ````caret```, que incluye varios modelos de aprendizaje automático y formas de acondicionar los datos para aplicar dichos modelos. [Aquí](http://topepo.github.io/caret/index.html) hay un muy buen bookdown que repasa muchas de las *funcionalidades* de ```caret```.

2. Cargamos los datos
```{r}
jugadores <- read.csv("C:/Users/Usuario/Documents/GitHub/futbol-data-science/clase-8/jugadores_superliga_argentina.csv", sep = ',', header = TRUE, encoding = 'UTF-8')
glimpse(jugadores)
unique(jugadores$position)
jugadores$es_CF <- ifelse(grepl("CF",jugadores$position), "si", "no")
jugadores <- jugadores %>% sample_n(10000)
jugadores <- jugadores %>% select(-short_passes_accurate, -total_short_passes, -team, -player, -match, -competition, -date, -position, -...72, -...73)

jugadores <- na.omit(jugadores)

```

Vamos a preparar los datos para el modelo, primero seteando una semilla para asegurar la replicabilidad de los resultados del modelo. La semilla genera que, aunque la data se divida de manera aleatoria, pero el método de lectura va a ser el mismo haciendo que los resultados sean los mismos si se corre el mismo modelo. También vamos a separar el dataset de forma aleatoria en un conjunto de entrenamiento y un conjunto de test.

3. Seteamos semilla y generamos partición entre train y test

```{r}
set.seed(3033)
#el parámetro p marca la proporción del dataset que va a estar destinada a entrenamiento. también le indicamos la variable target.
intrain <- createDataPartition(y = jugadores$es_CF, p= 0.7, list = FALSE)
training <- jugadores[intrain,]
testing <- jugadores[-intrain,]
#chequeamos como quedamor training y test
dim(training) 
dim(testing)
```

Caret provee una función para entrenar diferentes modelos. Primero seteamos una función llamada ````trainControl()``` donde definimos el método para controlar el entrenamiento. Con el parámetro de ```method``` indicamos el método de resampleo. En este caso usamos "repeated cross-validation". Con el parámetro ```number``` seteamos la cantidad de iteraciones de resampleo. El parámetro ```repeats``` marca la cantidad de "folds" para realizar nuestra operación.

4. Generamos nuestra función de control en training

```{r}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
```

Antes de entrenar nuestro árbol de decisión, seteamos la semilla. Al entrenar, paso la variable target ("V7"), el conjunto de datos, el método (es decir el modelo, en este caso "rpart"), los parámetros (que en este caso es una lista que contiene un split por ganancia de información), el método de control (definido como lista anteriormente).

5. Generamos el entrenamiento de RPART

```{r}
set.seed(1234)
modelo_arbol <- train(es_CF ~., data = training, method = "rpart",
                   parms = list(split = "information"),
                   trControl=trctrl,
                   tuneLength = 10)
```

6. Chequeamos el resultado del modelo

```{r}
modelo_arbol
```

7. Podemos visualizar el árbol de decisión que quedó generado, como también varias características del modelo.

```{r}
#metodo usado
modelo_arbol$method
#modelo mejor "tuneado". Es el que el parámetro cp (complexity parameter) es menor.
modelo_arbol$bestTune
#ploteamos
prp(modelo_arbol$finalModel, box.palette = "Reds", tweak = 1.2)
```

# Predicción

Vamos a ver cómo el modelo entrenado predice los valores de ```test```. Cuidado! Accuracy es una medida que puede omitir sesgos enormes del modelo. Se usa a modo orientativo aquí, se puede combinar con otras medidas como la curva ROC o las que vimos en las slides (recall, f1, precision, etc.).

8. Realizamos las predicciones

```{r}
#vamos a predecir la clase del primer registro de test
testing[1,'es_CF']
#vemos que el modelo predice bien!
predict(modelo_arbol, newdata = testing[1,])

#vamos a analizar las predicciones de todo el testing
test_pred <- predict(dtree_fit, newdata = testing)
testing$es_CF <- as.factor(testing$es_CF)
confusionMatrix(test_pred, testing$es_CF)  #Chequeamos "accuracy"
```

9. También puedo probar entrenar el árbol de decisión con otro criterio de split (índice gini por ejemplo).

```{r}
set.seed(3333)
modelo_arbol_gini <- train(es_CF ~., data = training, method = "rpart",
                   parms = list(split = "gini"),
                   trControl=trctrl,
                   tuneLength = 10)
modelo_arbol_gini

prp(modelo_arbol_gini$finalModel, box.palette = "Blues", tweak = 1.2)

# Predicción

test_pred_gini <- predict(modelo_arbol_gini, newdata = testing)
confusionMatrix(test_pred_gini, testing$es_CF )  #Chequear accuracy
```

Caret tiene muchísimos [modelos disponibles](https://rdrr.io/cran/caret/man/models.html) para utilizar. Lo bueno es que la estructura de preparación de datos es similar, la del paquete. Con lo cual con lo que vimos hoy, lo pueden replicar para el modelo disponible que gusten.

Los outputs de modelos se imprimen en consola, para manejarlos de manera más tidy y en consonancia con *tidyverse* podemos usar [broom](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) o [modelr](https://modelr.tidyverse.org/); tal como hicimos con la regresión logística la clase pasada.